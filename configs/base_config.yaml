experiment_name: "Advanced_HHSTF_Maxed"

seed: 42
debug: false
test: false

data:
  data_dir: "/root/Mice-Social-Action-V2/data/"
  batch_size: 2048
  num_workers: 8
  window_size: 64
  preload: true
  pin_memory: true
  prefetch_factor: 2        # 降低预取以释放更多内存给后处理
  persistent_workers: false # 强力释放: epoch 结束时释放 worker 内存
  cache_size: 2048          # 增加缓存索引大小
  
  sampling:
    strategy: "action_rich" # Options: "uniform", "action_rich" (oversample rare classes)
    bias_factor: 5.0

  preprocessing:
    target_fps: 30
    fix_fps: true
    interpolate_nans: true
    unify_body_parts: true
    view: "egocentric" # Options: "allocentric", "egocentric" (mouse-centered)
    
  features:
    enable_strong_features: true
    use_distances: true
    use_velocity: true
    use_acceleration: true
    use_jerk: true 
    use_angles: true
    use_relative_angles: true
    use_body_features: true
    use_window_stats: false
    window_sizes: [5, 15, 30]

  augmentation:
    enabled: true
    flip: true
    rotate: true
    time_stretch: false
    noise: 0.01

model: 
  spatial_encoder:
    enabled: true
    type: "gat" # Options: "spatialGNN" (MLP-like), "st_gcn" (Spatio-Temporal GCN), "gat" (Graph Attention)
    use_adj: true # Whether to use adjacency matrix constraints
    num_nodes: 7 # Number of keypoints/nodes after unification (set based on dataset)
    hidden_dim: 128
    num_layers: 4
    dropout: 0.1
    
  temporal_backbone:
    type: "squeezeformer" # Options: "squeezeformer" (Attention+Conv), "wavenet" (Dilated Conv), "transformer", "multi_scale_cnn"
    input_dim: 0
    hidden_dim: 512
    num_layers: 8
    kernel_size: 3
    dropout: 0.2
    transformer_heads: 16
    
  fusion:
    type: "concat" # Options: "attention" (Modulation), "concat" (Concatenation), "gated" (Learned Mix)
    hidden_dim: 1024
    dropout: 0.1
    
  classifier:
    num_classes: 76
    hidden_dim: 512
    
  context_adapter:
    enabled: true
    embedding_dim: 16
    use_subject_ids: true # New: Whether to use individual mouse IDs (caution: risk of overfitting)

training:
  optimizer: "fused_adamw"
  epochs: 200
  eval_interval: 10
  stop_loss_threshold: 0.0001
  learning_rate: 0.001
  weight_decay: 0.0001
  scheduler: "cosine" # Options: "cosine", "step", "plateau"
  loss_type: "new_focal" # Options: "focal" (fixed weight), "new_focal" (dataset-aware weights), "ce", "bce", "ohem", "macro_soft_f1"
  pos_weight: 12.0
  focal_gamma: 2.0
  focal_alpha: 0.25
  dynamic_pos_weight: false
  ohem_percent: 0.7
  mask_unlabeled: true
  save_dir: "/root/autodl-tmp/checkpoints/"
  torch_compile: true
  ema_enabled: false
  ema_decay: 0.999

cross_validation:
  enabled: false
  n_folds: 5

post_processing:
  n_jobs: 8
  threshold_strategy: "optimize" # Options: "optimize" (Grid Search), "kaggle" (Hardcoded per-lab), "fixed" (0.5)
  optimize_thresholds: true
  tie_breaking: "kaggle" # Options: "none", "z_score", "argmax", "kaggle" (Rule-based)
  smoothing:
    method: "ema" # Options: "median_filter", "ema", "none"
    window_size: 7
    alpha: 0.3
  gap_filling:
    max_gap: 10
    min_duration: 5


